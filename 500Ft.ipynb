{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primitive KML/Z Loader \n",
    "\n",
    "## General Info \n",
    "\n",
    "This is based off of `fastkml` \n",
    "\n",
    "## Motivation \n",
    "\n",
    "Existing libraries are pythonic -- they load for use in an object-oriented sense. Instead, I needed something that could load these into simple Numpy/Pandas objects and interact with the data in a rational form. Thus, I'm creating this, to hopefully be able to read through KML and eventually KMZ files and create a comprehensive representation of the data stored. It will, however, by necessity, lose some description statistics. \n",
    "\n",
    "## Goals \n",
    "\n",
    "### KML Parsing \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration \n",
    "distsInFeet = [500, 1320, 1500]       # Different layers\n",
    "RESOLUTION  = distsInFeet[0]//2 - 10  # Resolution of the map \n",
    "CIRC_CNT    = 50                      # Resolution of each circle \n",
    "LAYERS_FILE = \"f_shapes.js\"           # File to save Javascript Object to \n",
    "L_VAR_NAME  = \"o_shapes\"              # Name of the variable in the LAYERS_FILE javascript\n",
    "\n",
    "CORE_FILE_WE= True                    # Whether to recompute the core file \n",
    "CORE_FILE   = \"shapes.js\"             # Output location \n",
    "C_VAR_NAME  = \"shapes\"                # Name of variable in CORE_FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastkml import kml\n",
    "import shapely \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import lxml \n",
    "import json \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy as sp\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from shapely.ops import cascaded_union\n",
    "\n",
    "#garbage managmeent \n",
    "import gc \n",
    "\n",
    "global counter\n",
    "counter = 0 \n",
    "def get_id_from_description(description_string, mark_config = \"OBJECTID\"): \n",
    "    global counter\n",
    "    if description_string is not None: \n",
    "        string = description_string\n",
    "        string = ' '.join(string.replace(\"\\n\", \"\").split())\n",
    "        string = (string[string.find(\"<tr>\"):])\n",
    "        string = \"<root>\" + string + \"</root>\"\n",
    "        tree = lxml.etree.XML(string)\n",
    "        for row in tree.getchildren(): \n",
    "            f = row.getchildren()[0]\n",
    "            if f.text == mark_config: \n",
    "                return int(row.getchildren()[1].text)\n",
    "    counter += 1\n",
    "    return counter \n",
    "\n",
    "def get_coords(kml_object, resolution=1, mark_config=\"Beat\"): \n",
    "    while (isinstance(list(kml_object.features())[0], kml.Document) \\\n",
    "           or isinstance(list(kml_object.features())[0], kml.Folder)): \n",
    "        kml_object = list(kml_object.features())[0]\n",
    "    frames = {} \n",
    "    for k in kml_object.features(): \n",
    "        geom = shapely.geometry.mapping(k.geometry)\n",
    "        #now convert \n",
    "        arr = geom['coordinates']\n",
    "        if (len(arr) == 1): \n",
    "            arr = [arr] \n",
    "        paths = []\n",
    "        for path in arr:\n",
    "            path = path[0]\n",
    "            nparr = np.array(path, dtype=float) \n",
    "            subpath = []\n",
    "            for i in range(0, nparr.shape[0], resolution): \n",
    "                row = nparr[i, :].tolist() \n",
    "                subpath.append({\"lng\": row[0], \"lat\": row[1]})\n",
    "            paths.append(subpath) \n",
    "        geom['coordinates'] = paths \n",
    "        frames[get_id_from_description(k.description, mark_config)] = geom  \n",
    "    return frames \n",
    "\n",
    "if CORE_FILE_WE: \n",
    "    with open(\"data/gtboundary_layer.kml\", 'rt', encoding='utf-8') as myfile: \n",
    "        doc = myfile.read() \n",
    "\n",
    "    f = kml.KML() \n",
    "    f.from_string(doc) \n",
    "\n",
    "    frames = get_coords(f, resolution=1, mark_config=\"FID\") \n",
    "\n",
    "    #write to file \n",
    "    with open(CORE_FILE, \"w\") as f:\n",
    "        s = json.dumps(frames)\n",
    "        s = \"var \" + C_VAR_NAME + \"= \" + s; \n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have to conver this to 500 feet boundary \n",
    "\n",
    "first let's calculate what 1 foot is in terms of longitude and latitude \n",
    "\n",
    "This doesn't have to be too exact, so some error is fine \n",
    "\n",
    "Thus, we'll define our vectors as such: \n",
    "\n",
    "POSTIVE X is MORE POSITIVE LONGITUDE \n",
    "\n",
    "POSITIVE Y is MORE POSITIVE LATITUDE \n",
    "\n",
    "We'll be using a reverse haversine implementation \n",
    "\n",
    "The Haversine Formula Says: \n",
    "$$ hav \\left(\\frac d r\\right) = hav(\\phi_2 - \\phi_1) + \\cos(\\phi_1)\\cos(\\phi_2) hav(\\lambda_2 - \\lambda_1)$$\n",
    "where\n",
    "$$ \n",
    "hav(\\theta) = \\sin^2 \\left( \\frac \\theta 2 \\right) = \\frac {1 - cos(\\theta) } {2} $$\n",
    "and $\\phi$ is latitude, $\\lambda$ is longitude, both in radians "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hav(theta): \n",
    "    return (1 - np.cos(theta)) / 2\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2): \n",
    "    #we expect radians as in put \n",
    "    return hav(lat2 - lat1) + np.cos(lat1) * np.cos(lat2) * hav(lon2 - lon1) \n",
    "\n",
    "def calc_distance(**k): \n",
    "    havs = haversine(k[\"lon1\"], k[\"lat1\"], k[\"lon2\"], k[\"lat2\"])\n",
    "    c =  2 * np.arctan2(np.sqrt(havs), np.sqrt(1 - havs)) \n",
    "    invs = 6371e3 * c  \n",
    "    return invs\n",
    "def meters_to_feet(x): \n",
    "    return 3.28084 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll find the average longitude and latitude of our dataset. Then, we'll compute the distance between longitude, holding lat constant, and vice versa. The inverse will give us a lon-lat vector for unit distance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find vals \n",
    "lats = [] \n",
    "lngs = [] \n",
    "for k in frames:\n",
    "    for b in frames[k]['coordinates']: \n",
    "        for a in b: \n",
    "            lats.append(a['lat'])\n",
    "            lngs.append(a['lng'])      \n",
    "\n",
    "#compute means \n",
    "mean_lat = np.deg2rad(np.mean(lats))\n",
    "mean_lon = np.deg2rad(np.mean(lngs))\n",
    "\n",
    "#and max/min \n",
    "min_lat = np.deg2rad(min(lats)) \n",
    "max_lat = np.deg2rad(max(lats))\n",
    "\n",
    "min_lon = np.deg2rad(min(lngs)) \n",
    "max_lon = np.deg2rad(max(lngs)) \n",
    "\n",
    "#now find the distances \n",
    "movement_along_lat = meters_to_feet(calc_distance(lon1 = min_lon, \n",
    "                                                 lat1 = mean_lat, \n",
    "                                                 lon2 = max_lon, \n",
    "                                                 lat2 = mean_lat))\n",
    "movement_along_lng = meters_to_feet(calc_distance(lon1 = mean_lon, \n",
    "                                                 lat1 = min_lat, \n",
    "                                                 lon2 = mean_lon, \n",
    "                                                 lat2 = max_lat))\n",
    "coordVects = np.zeros((2, len(distsInFeet)))\n",
    "for i, v in enumerate(distsInFeet): \n",
    "    distInFeet = v \n",
    "    LonPer500Ft = np.rad2deg((max_lon - min_lon) / (movement_along_lat / distInFeet))\n",
    "    LatPer500Ft = np.rad2deg((max_lat - min_lat) / (movement_along_lng / distInFeet))\n",
    "    coordVects[:, i] = [LonPer500Ft, LatPer500Ft]\n",
    "distInFeet = distsInFeet[0]\n",
    "del lats \n",
    "del lngs \n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to interpolate to fill in any gaps. We'll use a resolution of 250 as half the required space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-826173289c0f>, line 97)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-826173289c0f>\"\u001b[0;36m, line \u001b[0;32m97\u001b[0m\n\u001b[0;31m    s = \"var \" + VAR_NAME +   = \" + s;\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Now, linear interpolation to increase resolution: \n",
    "def get_distance_in_feet(p1, p2): \n",
    "    return meters_to_feet(calc_distance(lon1 =  np.deg2rad(p1['lng']), \n",
    "                                       lon2 = np.deg2rad(p2['lng']), \n",
    "                                       lat1 = np.deg2rad(p1['lat']), \n",
    "                                       lat2 = np.deg2rad(p2['lat'])))\n",
    "def interpolate(p1, p2): \n",
    "    return {'lat': (p1['lat'] + p2['lat'])/2, \n",
    "            'lng': (p1['lng'] + p2['lng'])/2}\n",
    "\n",
    "print(\"Interpolating...\")\n",
    "count = 0 \n",
    "for f in frames: \n",
    "    for vi, v in enumerate(frames[f]['coordinates']): \n",
    "        k = v \n",
    "        finishedInterpolating = False\n",
    "        inter_count = 0 \n",
    "        while not finishedInterpolating:\n",
    "            finishedInterpolating = True \n",
    "            interpolated = [] \n",
    "            for i in range(0, len(k) - 1): \n",
    "                interp = None\n",
    "                if get_distance_in_feet(k[i], k[i + 1]) > RESOLUTION: \n",
    "                    #average coord \n",
    "                    interp = interpolate(k[i], k[i + 1])\n",
    "                interpolated.append(k[i])\n",
    "                if interp is not None: \n",
    "                    finishedInterpolating = False\n",
    "                    interpolated.append(interp) \n",
    "                interpolated.append(k[i + 1]) \n",
    "            k = interpolated \n",
    "            inter_count += 1\n",
    "        frames[f]['coordinates'][vi] = k \n",
    "        count += 1\n",
    "del interpolated \n",
    "del k \n",
    "del v \n",
    "gc.collect() \n",
    "\n",
    "#Some functions to use later \n",
    "def zip_coordinates(coords): \n",
    "    xs = list(map(lambda x: x['lng'], coords))\n",
    "    ys = list(map(lambda y: y['lat'], coords))\n",
    "    return (xs, ys) \n",
    "\n",
    "def plot_dict_coors_on_ax(coords, ax, shape=False): \n",
    "    xs, ys = zip_coordinates(coords)\n",
    "    if not shape: \n",
    "        ax.scatter(xs, ys) \n",
    "    else: \n",
    "        ax.plot(xs, ys)\n",
    "    return ax \n",
    "\n",
    "\n",
    "#Let's go through and regenerate polygons for everything again \n",
    "#Ellipse Template \n",
    "print(\"Merging...\")\n",
    "final_frame = {} \n",
    "for frame_no, dfeet in enumerate(distsInFeet): \n",
    "    print(\"Frame {} of {}\".format(frame_no + 1, len(distsInFeet)))\n",
    "    circle = np.array([i for i in np.linspace(0, 2 * np.pi, CIRC_CNT)]).T \n",
    "    circle = circle.reshape(circle.shape[0], 1)\n",
    "    circle = np.hstack((np.cos(circle), np.sin(circle))) \n",
    "    circle = np.multiply(coordVects[:, frame_no].tolist(), circle) \n",
    "    final_shapes = []\n",
    "    count = 0 \n",
    "    for k in frames: \n",
    "        for j in frames[k]['coordinates']: \n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            coordinates = zip_coordinates(j) \n",
    "            #zip em up \n",
    "            zip_coor = list(zip(*coordinates)) \n",
    "            #And now create our shape \n",
    "            ogShape = shapely.geometry.polygon.Polygon(zip_coor)\n",
    "            #And create our circles \n",
    "            circles = [ogShape] \n",
    "            for point in zip_coor: \n",
    "                #generate circle \n",
    "                circles.append(shapely.geometry.polygon.Polygon(np.add(point, circle))) \n",
    "            #Create a Union \n",
    "            union_shape = cascaded_union(circles)\n",
    "\n",
    "            #Again, extract the lat-lon coordinates from this. \n",
    "            final_shapes.append(union_shape) \n",
    "            count += 1\n",
    "\n",
    "    final_shape = cascaded_union(final_shapes)\n",
    "    #convert to our JSON version \n",
    "    points_array = [] \n",
    "    for k in zip(*final_shape.exterior.xy):\n",
    "        points_array.append({'lng': k[0], 'lat': k[1]})\n",
    "    final_frame[frame_no] =  {'coordinates': [points_array]}\n",
    "    print()\n",
    "print(\"Saving...\") \n",
    "with open(LAYERS_FILE, \"w\") as f:\n",
    "    s = json.dumps(final_frame)\n",
    "    s = \"var \" + L_VAR_NAME + \" = \" + s; \n",
    "    f.write(s)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data]",
   "language": "python",
   "name": "conda-env-data-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
